{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9657262b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gradio as gr\n",
    "from transformers import (\n",
    "    AutomaticSpeechRecognitionPipeline,\n",
    "    WhisperForConditionalGeneration,\n",
    "    WhisperTokenizer,\n",
    "    WhisperProcessor,\n",
    ")\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "\n",
    "# load the trained peft model\n",
    "peft_model_id = \"smangrul/openai-whisper-large-v2-LORA-colab\"\n",
    "language = \"Marathi\"\n",
    "task = \"transcribe\"\n",
    "peft_config = PeftConfig.from_pretrained(peft_model_id)\n",
    "model = WhisperForConditionalGeneration.from_pretrained(peft_config.base_model_name_or_path)\n",
    "\n",
    "model = PeftModel.from_pretrained(model, peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2490e020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the model in eval mode to merge the lora weights into the base model weights\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47611758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the base model via its `save_pretrained` method to save the model in pretrained model format\n",
    "# required for Optimum's ONNX converter\n",
    "model.get_base_model().save_pretrained(\"./temp_lora_whisper_large_v2_mr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6f500f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model and covert to ORT using Optimum\n",
    "# ignore the warning specifying lora_* layers were not used for initializing model.\n",
    "# They are already merged in base model's weights\n",
    "from optimum.onnxruntime import ORTModelForSpeechSeq2Seq\n",
    "\n",
    "model = ORTModelForSpeechSeq2Seq.from_pretrained(\n",
    "    \"./temp_lora_whisper_large_v2_mr\", from_transformers=True, provider=\"CUDAExecutionProvider\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60de4e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "language = \"Marathi\"\n",
    "task = \"transcribe\"\n",
    "tokenizer = WhisperTokenizer.from_pretrained(peft_config.base_model_name_or_path, language=language, task=task)\n",
    "processor = WhisperProcessor.from_pretrained(peft_config.base_model_name_or_path, language=language, task=task)\n",
    "feature_extractor = processor.feature_extractor\n",
    "forced_decoder_ids = processor.get_decoder_prompt_ids(language=language, task=task)\n",
    "pipe = AutomaticSpeechRecognitionPipeline(model=model, tokenizer=tokenizer, feature_extractor=feature_extractor)\n",
    "\n",
    "\n",
    "def transcribe(audio):\n",
    "    text = pipe(audio, generate_kwargs={\"forced_decoder_ids\": forced_decoder_ids}, max_new_tokens=255)[\"text\"]\n",
    "    return text\n",
    "\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=transcribe,\n",
    "    inputs=gr.Audio(source=\"microphone\", type=\"filepath\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"PEFT LoRA + INT8 Whisper Large V2 Marathi\",\n",
    "    description=\"Realtime demo for Marathi speech recognition using `PEFT-LoRA+INT8` fine-tuned Whisper Large V2 model.\",\n",
    ")\n",
    "\n",
    "iface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
